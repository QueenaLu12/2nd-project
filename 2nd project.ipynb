{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanker News Dataset Analysis\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. \n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14'], ['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']]\n"
     ]
    }
   ],
   "source": [
    "opened_file = open(\"HN_posts_year_to_Sep_26_2016.csv\")\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "list_file = list(read_file)\n",
    "hn_header = list_file[0]\n",
    "hn = list_file[1:]\n",
    "\n",
    "print(hn_header)\n",
    "print(hn[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last screen, we separated the \"ask posts\" and the \"show posts\" into two list of lists named ask_posts and show_posts. Below are the first five rows in the ask_posts list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12578335',\n",
       "  'Show HN: Finding puns computationally',\n",
       "  'http://puns.samueltaylor.org/',\n",
       "  '2',\n",
       "  '0',\n",
       "  'saamm',\n",
       "  '9/26/2016 0:36'],\n",
       " ['12578182',\n",
       "  'Show HN: A simple library for complicated animations',\n",
       "  'https://christinecha.github.io/choreographer-js/',\n",
       "  '1',\n",
       "  '0',\n",
       "  'christinecha',\n",
       "  '9/26/2016 0:01'],\n",
       " ['12578098',\n",
       "  'Show HN: WebGL visualization of DNA sequences',\n",
       "  'http://grondilu.github.io/dna.html',\n",
       "  '1',\n",
       "  '0',\n",
       "  'grondilu',\n",
       "  '9/25/2016 23:44'],\n",
       " ['12577991',\n",
       "  'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules',\n",
       "  'https://github.com/jakebian/zeal',\n",
       "  '2',\n",
       "  '0',\n",
       "  'dbranes',\n",
       "  '9/25/2016 23:17'],\n",
       " ['12577142',\n",
       "  'Show HN: Jumble  Essays on the go #PaulInYourPocket',\n",
       "  'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8',\n",
       "  '1',\n",
       "  '1',\n",
       "  'ryderj',\n",
       "  '9/25/2016 20:06'],\n",
       " ['12576813',\n",
       "  'Show HN: Learn Japanese Vocab via multiple choice questions',\n",
       "  'http://japanese.vul.io/',\n",
       "  '1',\n",
       "  '1',\n",
       "  'soulchild37',\n",
       "  '9/25/2016 19:06']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hn_header)\n",
    "ask_posts[:6]\n",
    "print(\"\\n\")\n",
    "show_posts[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average number of comments on ask posts and assign it to avg_ask_comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94986\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    comments = int(row[4])\n",
    "    total_ask_comments += comments\n",
    "print(total_ask_comments)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "num_ask_comments = len(ask_posts)\n",
    "avg_ask_comments = total_ask_comments / num_ask_comments # avg number of comments for each title\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average number of comments on show posts and assign it to avg_show_comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49633\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    comments = int(row[4])\n",
    "    total_show_comments += comments\n",
    "print(total_show_comments)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "num_show_comments = len(show_posts)\n",
    "avg_show_comments = total_show_comments / num_show_comments # avg number of comments for each title\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that ask posts receive more average comments. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "- Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n",
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at,num_comments])\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for item in result_list:\n",
    "    create_date = item[0]\n",
    "    date_format = \"%m/%d/%Y %H:%M\"\n",
    "    create_date = dt.datetime.strptime(create_date,date_format)\n",
    "    hours = create_date.strftime(\"%H\")\n",
    "    if hours not in counts_by_hour:\n",
    "        counts_by_hour[hours] = 1\n",
    "        comments_by_hour[hours] = item[1]\n",
    "    else:\n",
    "        counts_by_hour[hours] += 1\n",
    "        comments_by_hour[hours] += item[1]\n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the average number of comments for posts created during each hour of the day, and stored the results in a list of lists named avg_by_hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, (comments_by_hour[hour] / counts_by_hour[hour])])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.676470588235293, '15'], [16.31756756756757, '13'], [12.380116959064328, '12'], [11.137546468401487, '02'], [10.684397163120567, '10'], [9.7119341563786, '04']]\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(sorted_swap[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the str.format() method to print the hour and average in the following format: \"15:00: 38.59 average comments per post\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n",
      "04:00: 9.71 average comments per post\n",
      "14:00: 9.69 average comments per post\n",
      "17:00: 9.45 average comments per post\n",
      "08:00: 9.19 average comments per post\n",
      "11:00: 8.96 average comments per post\n",
      "22:00: 8.80 average comments per post\n",
      "05:00: 8.79 average comments per post\n",
      "20:00: 8.75 average comments per post\n",
      "21:00: 8.69 average comments per post\n",
      "03:00: 7.95 average comments per post\n",
      "18:00: 7.94 average comments per post\n",
      "16:00: 7.71 average comments per post\n",
      "00:00: 7.56 average comments per post\n",
      "01:00: 7.41 average comments per post\n",
      "19:00: 7.16 average comments per post\n",
      "07:00: 7.01 average comments per post\n",
      "06:00: 6.78 average comments per post\n",
      "23:00: 6.70 average comments per post\n",
      "09:00: 6.65 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap:\n",
    "    time_format = \"{}: {:.2f} average comments per post\"\n",
    "    swap = dt.datetime.strptime(row[1],\"%H\")\n",
    "    swap = swap.strftime(\"%H:%M\")\n",
    "    swap = time_format.format(swap,row[0])\n",
    "    print(swap)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 15:00 has the highest number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
